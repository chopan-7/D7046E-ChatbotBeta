{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/chopan-7/D7046E-ChatbotBeta/blob/main/Chatbot_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/thomas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from ChatbotBeta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbyOxxU0pOuO"
   },
   "source": [
    "# Sentiment classification model\n",
    "#### Creating model and dataset\n",
    "Preprocess IMDB dataset and create a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = ChatbotDataset(\"./processed_IMDB_Dataset10000.txt\")\n",
    "dataset.create()\n",
    "model = ClassyModel(dataset.vocab_size, 150, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters, uncomment and modify to tweak the model\n",
    "#model.epochs = 1\n",
    "#model.lr = 0.001\n",
    "#model.loss_function = nn.CrossEntropyLoss()\n",
    "#model.optimizer = torch.optim.Adam(model.parameters(), model.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [160/160] - Loss: 0.26572421193122864 - Acc.: 90.2%"
     ]
    }
   ],
   "source": [
    "model.train(dataset.train_loader, dataset.validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset IMDB_Dataset.pt is saved to ./\n"
     ]
    }
   ],
   "source": [
    "dataset.save(\"IMDB_Dataset.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model IMDB_Model.pt is saved to ./\n"
     ]
    }
   ],
   "source": [
    "model.saveModel(\"IMDB_Model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IntentDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b6a66a16768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoodIntent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntentDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgoodIntent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./good_intent.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IntentDataset' is not defined"
     ]
    }
   ],
   "source": [
    "goodIntent = IntentDataset()\n",
    "goodIntent.bow_preprocess(\"./good_intent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 1.6276\n"
     ]
    }
   ],
   "source": [
    "goodModel = NeuralNet(len(goodIntent), 8, len(goodIntent.tags))\n",
    "goodModel.train(goodIntent.trainLoader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model goodIntent_Model.pt is saved to ./\n",
      "Saving dataset goodIntent_Dataset.pt to ./\n"
     ]
    }
   ],
   "source": [
    "goodModel.saveModel(\"goodIntent_Model.pt\")\n",
    "goodIntent.save(\"goodIntent_Dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Chatbot_trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
